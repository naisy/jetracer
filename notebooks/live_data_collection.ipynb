{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython Libraries for display and widgets\n",
    "import ipywidgets\n",
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "import torch\n",
    "import torchvision\n",
    "import threading\n",
    "import time\n",
    "from jetracer.utils import preprocess\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "\n",
    "import cv2\n",
    "import ipywidgets\n",
    "from traitlets import observe\n",
    "from IPython.display import display\n",
    "from jetcam.utils import bgr8_to_jpeg\n",
    "from jupyter_clickable_image_widget import ClickableImageWidget\n",
    "from ipywidgets import Button, Layout, Textarea, HBox, VBox, Label\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import glob\n",
    "import PIL.Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Camera and Motor Interface\n",
    "from jetcam.utils import bgr8_to_jpeg\n",
    "\n",
    "# Python basic pakcages for image annotation\n",
    "from uuid import uuid1\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "current_milli_time = lambda: int(round(time.time() * 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo jetson | sudo -S systemctl restart nvargus-daemon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetcam.csi_camera import CSICamera\n",
    "# from jetcam.usb_camera import USBCamera\n",
    "\n",
    "camera = CSICamera(width=224, height=224, capture_fps=10)\n",
    "# camera = USBCamera(width=224, height=224)\n",
    "\n",
    "camera.running = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_style = {'description_width': 'initial'}\n",
    "widget_width = Layout(width=str(camera.width)+'px')\n",
    "widget_width_half = Layout(width=str(camera.width/2)+'px')\n",
    "l = Layout(flex='0 1 auto', height='100px', min_height='100px', width='auto')\n",
    "process_widget = ipywidgets.Textarea(description='ログ', value='', layout=l, style=description_style)\n",
    "\n",
    "process_no = 0\n",
    "def write_log(msg):\n",
    "    global process_widget, process_no\n",
    "    process_no = process_no + 1\n",
    "    process_widget.value = str(process_no) + \": \" + msg + \"\\n\" + process_widget.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_clickable_image_widget import ClickableImageWidget\n",
    "DATASET_DIR = 'dataset_xy'\n",
    "\n",
    "\n",
    "# we have this \"try/except\" statement because these next functions can throw an error if the directories exist already\n",
    "try:\n",
    "    os.makedirs(DATASET_DIR)\n",
    "except FileExistsError:\n",
    "    print('Directories not created becasue they already exist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cameraの読み込み。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ウィジェットのdescriptionは幅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy(name):\n",
    "    \"\"\"\n",
    "    name:\n",
    "        dir/xy_unixtimemillisec_x_y.jpg\n",
    "        xy_unixtimemillisec_x_y.jpg\n",
    "    \"\"\"\n",
    "    pattern = '.*xy_(\\d+)_(\\d+)_(\\d+).*'\n",
    "    result = re.match(pattern, name)\n",
    "    if result:\n",
    "        millisec = result.group(1)\n",
    "        x = result.group(2)\n",
    "        y = result.group(3)\n",
    "    else:\n",
    "        millisec = 0\n",
    "        x = 0\n",
    "        y = 0\n",
    "    return x, y\n",
    "\n",
    "def get_millisec(name):\n",
    "    \"\"\"\n",
    "    name:\n",
    "        xy_unixtimemillisec_x_y.jpg\n",
    "    \"\"\"\n",
    "    pattern = '^xy_(\\d+)_(\\d+)_(\\d+).*'\n",
    "    result = re.match(pattern, name)\n",
    "    if result:\n",
    "        millisec = result.group(1)\n",
    "        x = result.group(2)\n",
    "        y = result.group(3)\n",
    "    else:\n",
    "        millisec = 0\n",
    "        x = 0\n",
    "        y = 0\n",
    "    return millisec\n",
    "\n",
    "def get_x(path):\n",
    "    \"\"\"Gets the x value from the image filename\"\"\"\n",
    "    return (float(int(path[3:6])) - 50.0) / 50.0\n",
    "\n",
    "def get_y(path):\n",
    "    \"\"\"Gets the y value from the image filename\"\"\"\n",
    "    return (float(int(path[7:10])) - 50.0) / 50.0\n",
    "\n",
    "class XYDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, directory, random_hflips=False):\n",
    "        self.directory = directory\n",
    "        self.image_paths = glob.glob(os.path.join(directory, '*.jpg'))\n",
    "        self.color_jitter = transforms.ColorJitter(0.2, 0.2, 0.2, 0.2)\n",
    "        self.refresh()\n",
    "        self.random_hflips = random_hflips\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "   \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        x_ratio, y_ratio = get_xy(image_path)\n",
    "        x = float(int(x_ratio)-50.0)/50.0\n",
    "        y = float(int(y_ratio)-50.0)/50.0\n",
    "\n",
    "        image = PIL.Image.open(image_path)\n",
    "\n",
    "        # ランダムに画像を水平反転する時、出力のxも対応するように反転する\n",
    "        if self.random_hflips:\n",
    "            if float(np.random.rand(1)) > 0.5:\n",
    "                image = transforms.functional.hflip(image)\n",
    "                x = -x\n",
    "\n",
    "        # 画像をモデル学習の入力用データフォーマットに変換する\n",
    "        image = self.color_jitter(image)\n",
    "        image = transforms.functional.resize(image, (224, 224))\n",
    "        image = transforms.functional.to_tensor(image)\n",
    "        image = image.numpy()[::-1].copy()\n",
    "        image = torch.from_numpy(image)\n",
    "        # ImageNetの正規化と同じパラメータでデータを正規化する\n",
    "        image = transforms.functional.normalize(image, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "        return image, torch.tensor([x, y]).float()\n",
    "\n",
    "    def refresh(self):\n",
    "        self.annotations = []\n",
    "        for image_path in glob.glob(os.path.join(self.directory, '*.jpg')):\n",
    "            x, y = get_xy(image_path)\n",
    "            self.annotations += [{\n",
    "                'image_path': image_path,\n",
    "                'x': x,\n",
    "                'y': y\n",
    "            }]\n",
    "\n",
    "dataset = XYDataset(DATASET_DIR, random_hflips=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# unobserve all callbacks from camera in case we are running this cell for second time\n",
    "camera.unobserve_all()\n",
    "\n",
    "# create image preview\n",
    "camera_widget = ClickableImageWidget(width=camera.width, height=camera.height)\n",
    "edit_widget = ClickableImageWidget(width=camera.width, height=camera.height)\n",
    "traitlets.dlink((camera, 'value'), (camera_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "no_widget = ipywidgets.IntText(description='no', style=description_style, layout=widget_width)\n",
    "\n",
    "# create widgets\n",
    "#IntSlider(description='A too long description', style=style)\n",
    "#count_widget = HBox([Label('count'), ipywidgets.IntText()])\n",
    "count_widget = ipywidgets.IntText(description='count', style=description_style, layout=widget_width)\n",
    "\n",
    "# manually update counts at initialization\n",
    "count_widget.value = len(glob.glob(os.path.join(DATASET_DIR, '*.jpg')))\n",
    "\n",
    "\n",
    "# カメラ画像を保存する機能を作成します。\n",
    "def save_snapshot(_, content, msg):\n",
    "    global DATASET_DIR, dataset, edit_widget, no_widget\n",
    "    if content['event'] == 'click':\n",
    "        data = content['eventData']\n",
    "        x = data['offsetX']\n",
    "        y = data['offsetY']\n",
    "        # save to disk\n",
    "        #dataset.save_entry(category_widget.value, camera.value, x, y)\n",
    "        x_ratio = int((x/224)*100)\n",
    "        y_ratio = int((y/224)*100)\n",
    "        filename = 'xy_%13d_%03d_%03d' % (current_milli_time(), x_ratio, y_ratio) + '.jpg'\n",
    "        image_path = os.path.join(DATASET_DIR, filename)\n",
    "        with open(image_path, 'wb') as f:\n",
    "            f.write(camera_widget.value)\n",
    "        \n",
    "        # display saved snapshot\n",
    "        snapshot = camera.value.copy()\n",
    "        snapshot = cv2.circle(snapshot, (x, y), 8, (0, 255, 0), 3)\n",
    "        edit_widget.value = bgr8_to_jpeg(snapshot)\n",
    "        count_widget.value = len(glob.glob(os.path.join(DATASET_DIR, '*.jpg')))\n",
    "        no_widget.value = count_widget.value\n",
    "        dataset.refresh()\n",
    "\n",
    "\n",
    "camera_widget.on_msg(save_snapshot)\n",
    "\n",
    "data_collection_widget = ipywidgets.HBox([\n",
    "    ipywidgets.VBox([\n",
    "        camera_widget,\n",
    "        Label('click to collect data'),\n",
    "        count_widget\n",
    "    ], layout=Layout(align_items='center')),\n",
    "    ipywidgets.VBox([\n",
    "        edit_widget,\n",
    "        Label('clicked point')\n",
    "    ], layout=Layout(align_items='center'))\n",
    "])\n",
    "\n",
    "display(data_collection_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "device = torch.device('cuda')\n",
    "output_dim = 2  # x, y coordinate\n",
    "\n",
    "# ALEXNET\n",
    "# model = torchvision.models.alexnet(pretrained=True)\n",
    "# model.classifier[-1] = torch.nn.Linear(4096, output_dim)\n",
    "\n",
    "# SQUEEZENET \n",
    "# model = torchvision.models.squeezenet1_1(pretrained=True)\n",
    "# model.classifier[1] = torch.nn.Conv2d(512, output_dim, kernel_size=1)\n",
    "# model.num_classes = len(dataset.categories)\n",
    "\n",
    "# RESNET 18\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Linear(512, output_dim)\n",
    "\n",
    "# RESNET 34\n",
    "# model = torchvision.models.resnet34(pretrained=True)\n",
    "# model.fc = torch.nn.Linear(512, output_dim)\n",
    "\n",
    "# DENSENET 121\n",
    "# model = torchvision.models.densenet121(pretrained=True)\n",
    "# model.classifier = torch.nn.Linear(model.num_features, output_dim)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "model_save_button = ipywidgets.Button(description='save model', layout=widget_width_half)\n",
    "model_load_button = ipywidgets.Button(description='load model', layout=widget_width_half)\n",
    "model_path_widget = ipywidgets.Text(description='model', value='road_following_model.pth', style=description_style, layout=widget_width)\n",
    "\n",
    "def load_model(c):\n",
    "    start = time.time()\n",
    "    write_log(model_path_widget.value + \"の読込処理を開始します。\")\n",
    "    model.load_state_dict(torch.load(model_path_widget.value))\n",
    "    process_time = time.time() - start\n",
    "    write_log(model_path_widget.value + \"の読込処理を終了しました(処理時間:{0:.3f}秒)。\".format(process_time))\n",
    "model_load_button.on_click(load_model)\n",
    "    \n",
    "def save_model(c):\n",
    "    start = time.time()\n",
    "    write_log(model_path_widget.value + \"の書込処理を開始します。\")\n",
    "    torch.save(model.state_dict(), model_path_widget.value)\n",
    "    process_time = time.time() - start\n",
    "    write_log(model_path_widget.value + \"の書込処理を終了しました(処理時間:{0:.3f}秒)。\".format(process_time))\n",
    "model_save_button.on_click(save_model)\n",
    "\n",
    "model_widget = ipywidgets.VBox([\n",
    "    model_path_widget,\n",
    "    ipywidgets.HBox([model_load_button, model_save_button]),\n",
    "])\n",
    "\n",
    "\n",
    "display(model_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Live Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "\n",
    "state_widget = ipywidgets.ToggleButtons(options=['stop', 'live'], description='state', value='stop', style=description_style)\n",
    "state_widget.style.button_width='50px'\n",
    "prediction_widget = ipywidgets.Image(format='jpeg', width=camera.width, height=camera.height)\n",
    "\n",
    "def live(state_widget, model, camera, prediction_widget):\n",
    "    while state_widget.value == 'live':\n",
    "        image = camera.value\n",
    "        preprocessed = preprocess(image)\n",
    "        output = model(preprocessed).detach().cpu().numpy().flatten()\n",
    "        x_pred = output[0]\n",
    "        y_pred = output[1]\n",
    "        #write_log(\"x_pred,y_pred = {},{}\".format(x_pred,y_pred))\n",
    "        x_ratio = x_pred/2 + 0.5\n",
    "        y_ratio = y_pred/2 + 0.5\n",
    "        #write_log(\"x_ratio,y_ratio = {},{}\".format(x_ratio,y_ratio))\n",
    "        x = int(camera.width * x_ratio)\n",
    "        y = int(camera.height * y_ratio)\n",
    "        #write_log(\"x,y = {},{}\".format(x,y))\n",
    "\n",
    "        prediction = image.copy()\n",
    "        prediction = cv2.circle(prediction, (int(x), int(y)), 8, (255, 0, 0), 3)\n",
    "        prediction_widget.value = bgr8_to_jpeg(prediction)\n",
    "            \n",
    "def start_live(change):\n",
    "    if change['new'] == 'live':\n",
    "        write_log(\"liveモードを開始します。\")\n",
    "        execute_thread = threading.Thread(target=live, args=(state_widget, model, camera, prediction_widget))\n",
    "        execute_thread.start()\n",
    "    else:\n",
    "        write_log(\"liveモードを停止します。\")\n",
    "\n",
    "state_widget.observe(start_live, names='value')\n",
    "\n",
    "live_execution_widget = ipywidgets.VBox([\n",
    "    prediction_widget,\n",
    "    Label('prediction'),\n",
    "    state_widget\n",
    "], layout=Layout(align_items='center'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
    "\n",
    "epochs_widget = ipywidgets.IntText(description='epochs', value=1, style=description_style, layout=widget_width)\n",
    "eval_button = ipywidgets.Button(description='evaluate', layout=widget_width_half)\n",
    "train_button = ipywidgets.Button(description='train', layout=widget_width_half)\n",
    "loss_widget = ipywidgets.FloatText(description='loss', style=description_style, layout=widget_width)\n",
    "progress_widget = ipywidgets.FloatProgress(min=0.0, max=1.0, description='progress', style=description_style, layout=widget_width)\n",
    "\n",
    "# create RMSELoss function\n",
    "def RMSELoss(yhat,y):\n",
    "    '''\n",
    "    yhat: predicted value\n",
    "    y: observed value\n",
    "    '''\n",
    "    return torch.sqrt(torch.mean((yhat-y)**2))\n",
    "\n",
    "criterion = RMSELoss\n",
    "\n",
    "\n",
    "class Progress(traitlets.HasTraits):\n",
    "    value = traitlets.Float()\n",
    "    total_value = 100\n",
    "\n",
    "    @observe('value')\n",
    "    def _on_value(self, change):\n",
    "       \n",
    "        self._update_progress()\n",
    "    \n",
    "    def _update_progress(self):\n",
    "        global progress_widget\n",
    "        progress_widget.value = self.value / self.total_value\n",
    "\n",
    "\n",
    "def train_eval(is_training):\n",
    "    global BATCH_SIZE, LEARNING_RATE, MOMENTUM, model, dataset, optimizer, eval_button, train_button, model_save_button, model_load_button, state_widget, accuracy_widget, loss_widget, progress_widget, state_widget\n",
    "    \n",
    "    try:\n",
    "        progress_widget.value = 0\n",
    "        #test_percent = 0.1 # テストデータ件数を10%にする\n",
    "        #num_test = int(test_percent * len(dataset))\n",
    "        #train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - num_test, num_test])\n",
    "        #write_log(\"dataset: {}\".format(len(dataset)))\n",
    "        #write_log(\"train_dataset: {}\".format(len(train_dataset)))\n",
    "        #write_log(\"test_dataset: {}\".format(len(test_dataset)))\n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            num_workers=0\n",
    "        )\n",
    "\n",
    "        state_widget.value = 'stop'\n",
    "        model_save_button.disabled = True\n",
    "        model_load_button.disabled = True\n",
    "        state_widget.disabled = True\n",
    "        train_button.disabled = True\n",
    "        eval_button.disabled = True\n",
    "        time.sleep(1)\n",
    "        start = time.time()\n",
    "        if is_training:\n",
    "            model = model.train()\n",
    "            write_log(\"{} Epochの学習を開始します。\".format(epochs_widget.value))\n",
    "        else:\n",
    "            # ドロップアウトを無効にする評価モード\n",
    "            model = model.eval()\n",
    "            write_log(\"評価モードで学習を開始します(1 Epochのみ)。\")\n",
    "\n",
    "        epoch_num = 1\n",
    "        progress = Progress()\n",
    "        progress.total_value = 8*len(dataset)/BATCH_SIZE\n",
    "        while epochs_widget.value > 0:\n",
    "            i = 0\n",
    "            sum_loss = 0.0\n",
    "            error_count = 0.0\n",
    "            epoch_start = time.time()\n",
    "            progress.value = 0\n",
    "            for images, xy in iter(train_loader):\n",
    "                progress.value += 1\n",
    "                # send data to device\n",
    "                images = images.to(device)\n",
    "                progress.value += 1\n",
    "                xy = xy.to(device)\n",
    "                progress.value += 1\n",
    "                if is_training:\n",
    "                    # zero gradients of parameters\n",
    "                    optimizer.zero_grad()\n",
    "                progress.value += 1\n",
    "\n",
    "                # execute model to get outputs\n",
    "                outputs = model(images)\n",
    "                progress.value += 1\n",
    "\n",
    "                # compute MSE loss over x, y coordinates for associated categories\n",
    "                loss = 0.0\n",
    "                loss += F.mse_loss(outputs, xy)\n",
    "                progress.value += 1\n",
    "\n",
    "                if is_training:\n",
    "                    # run backpropogation to accumulate gradients\n",
    "                    loss.backward()\n",
    "\n",
    "                    # step optimizer to adjust parameters\n",
    "                    optimizer.step()\n",
    "                progress.value += 1\n",
    "\n",
    "                # increment progress\n",
    "                i += 1\n",
    "                #progress_widget.value = i / len(dataset)*BATCH_SIZE\n",
    "                sum_loss += float(loss)\n",
    "                loss_widget.value = sum_loss / i\n",
    "                progress.value += 1\n",
    "                \n",
    "            if is_training:\n",
    "                process_time = time.time() - epoch_start\n",
    "                write_log(str(epoch_num)+\"Epoch目の学習が終了しました(処理時間:{0:.3f}秒)。\".format(process_time))\n",
    "                epochs_widget.value -= 1\n",
    "                epoch_num += 1\n",
    "            else:\n",
    "                write_log(\"20x\")\n",
    "                break\n",
    "    except e:\n",
    "        write_log(\"{}\".format(e))\n",
    "        pass\n",
    "    model = model.eval()\n",
    "    \n",
    "    model_save_button.disabled = False\n",
    "    model_load_button.disabled = False\n",
    "    state_widget.disabled = False\n",
    "    train_button.disabled = False\n",
    "    eval_button.disabled = False\n",
    "   \n",
    "    process_time = time.time() - start\n",
    "    if is_training:\n",
    "        write_log(\"すべての学習が終了しました(トータルの処理時間:{0:.3f}秒)。\".format(process_time))\n",
    "    else:\n",
    "        write_log(\"すべての評価が終了しました(トータルの処理時間:{0:.3f}秒)。\".format(process_time))\n",
    "        \n",
    "    state_widget.value = 'live'\n",
    "    \n",
    "train_button.on_click(lambda c: train_eval(is_training=True))\n",
    "eval_button.on_click(lambda c: train_eval(is_training=False))\n",
    "    \n",
    "train_eval_widget = ipywidgets.VBox([\n",
    "    epochs_widget,\n",
    "    progress_widget,\n",
    "    loss_widget,\n",
    "    ipywidgets.HBox([train_button, eval_button])\n",
    "])\n",
    "\n",
    "display(train_eval_widget)\n",
    "display(process_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(no):\n",
    "    \"\"\"\n",
    "    noは1からn番までの値で、ファイル番号を表す。\n",
    "    \"\"\"\n",
    "    global DATASET_DIR, img,load_flag,no_widget,edit_widget\n",
    "    filenames = os.listdir(DATASET_DIR)\n",
    "    filenames.sort()\n",
    "    if len(filenames) == 0:\n",
    "        no_widget.value = 0\n",
    "        write_log(\"データファイルが存在しません。\")\n",
    "        return\n",
    "    if no > len(filenames):\n",
    "        no = 1\n",
    "    if no < 1:\n",
    "        no = len(filenames)\n",
    "\n",
    "    no_widget.value = no\n",
    "    name = filenames[no -1]\n",
    "    write_log(str(no) + \"枚目の\" + name + \"を読込みます。\")\n",
    "    \n",
    "    x_ratio, y_ratio = get_xy(name)\n",
    "    x = int(float(x_ratio)/100*224)\n",
    "    y = int(float(y_ratio)/100*224)\n",
    "    img = cv2.imread(os.path.join(DATASET_DIR, name))\n",
    "    marked_img = img.copy()\n",
    "    marked_img = cv2.circle(marked_img, (int(x), int(y)), 8, (0, 255, 0), 3)\n",
    "    edit_widget.value = bgr8_to_jpeg(marked_img)\n",
    "    write_log(str(no) + \"枚目の\" + name + \"を読込みました。\")\n",
    "\n",
    "def prev_pic(c):\n",
    "    global img,load_flag\n",
    "    load_flag = True\n",
    "    no = no_widget.value\n",
    "    no = int(no) - 1\n",
    "    load_img(no)\n",
    "\n",
    "def next_pic(c):\n",
    "    global x,y,load_flag\n",
    "    load_flag = True\n",
    "    no = no_widget.value\n",
    "    no = int(no) + 1\n",
    "    load_img(no)\n",
    "\n",
    "def save_edit(_, content, msg):\n",
    "    global DATASET_DIR,dataset,img,x,y,load_flag,edit_widget,no_widget\n",
    "    if content['event'] == 'click' and load_flag == True:\n",
    "        #load_flag = False\n",
    "        data = content['eventData']\n",
    "        x = data['offsetX']\n",
    "        y = data['offsetY']\n",
    "        # save to disk\n",
    "        #dataset.save_entry(category_widget.value, camera.value, x, y)\n",
    "        x_ratio = int((x/224)*100)\n",
    "        y_ratio = int((y/224)*100)\n",
    "\n",
    "        filenames = os.listdir(DATASET_DIR)\n",
    "        filenames.sort()\n",
    "        old_file_name = filenames[no_widget.value -1]\n",
    "        old_file_path = os.path.join(DATASET_DIR, old_file_name)\n",
    "        write_log(\"old_file_path: {}\".format(old_file_path))\n",
    "        millisec = int(get_millisec(old_file_name))\n",
    "        new_file_name = 'xy_%13d_%03d_%03d' % (millisec, x_ratio, y_ratio) + '.jpg'\n",
    "        new_file_path = os.path.join(DATASET_DIR, new_file_name)\n",
    "        write_log(\"new_file_path: {}\".format(new_file_path))\n",
    "        os.rename(old_file_path, new_file_path)\n",
    "        \n",
    "        # display saved remarked_img\n",
    "        remarked_img = cv2.imread(new_file_path)\n",
    "        remarked_img = cv2.circle(remarked_img, (int(x), int(y)), 8, (0, 255, 0), 3)\n",
    "        edit_widget.value = bgr8_to_jpeg(remarked_img)\n",
    "        #count_widget.value = len(glob.glob(os.path.join(DATASET_DIR, '*.jpg')))\n",
    "        dataset.refresh()\n",
    "\n",
    "        \n",
    "        write_log(\"新しい座標で保存しました。\")\n",
    "edit_widget.on_msg(save_edit)\n",
    "prev_pic_button = ipywidgets.Button(description='prev', layout=widget_width_half)\n",
    "next_pic_button = ipywidgets.Button(description='next', layout=widget_width_half)\n",
    "\n",
    "prev_pic_button.on_click(prev_pic)\n",
    "next_pic_button.on_click(next_pic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following widget can be used to label a multi-class x, y dataset.  It supports labeling only one instance of each class per image (ie: only one dog), but multiple classes (ie: dog, cat, horse) per image are possible.\n",
    "\n",
    "Click the image on the top left to save an image of ``category`` to ``dataset`` at the clicked location.\n",
    "\n",
    "| Widget | Description |\n",
    "|--------|-------------|\n",
    "| dataset | Selects the active dataset |\n",
    "| category | Selects the active category |\n",
    "| epochs | Sets the number of epochs to train for |\n",
    "| train | Trains on the active dataset for the number of epochs specified |\n",
    "| evaluate | Evaluates the accuracy on the active dataset over one epoch |\n",
    "| model path | Sets the active model path |\n",
    "| load | Loads a model from the active model path |\n",
    "| save | Saves a model to the active model path |\n",
    "| stop | Disables the live demo |\n",
    "| live | Enables the live demo |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vb_data_collection_widget = ipywidgets.VBox([\n",
    "        camera_widget,\n",
    "        Label('click to collect data'),\n",
    "        count_widget,\n",
    "        train_eval_widget,\n",
    "        model_widget,\n",
    "    ], layout=Layout(align_items='center'))\n",
    "\n",
    "vb_edit_widget = VBox([\n",
    "    edit_widget,\n",
    "    Label('edit data'),\n",
    "    no_widget,\n",
    "    HBox([prev_pic_button, next_pic_button])],\n",
    "    layout=Layout(align_items='center')\n",
    ")\n",
    "\n",
    "\n",
    "all_widget = ipywidgets.VBox([\n",
    "\n",
    "    ipywidgets.HBox([vb_data_collection_widget,\n",
    "                     vb_edit_widget,\n",
    "                     live_execution_widget]), \n",
    "\n",
    "    process_widget\n",
    "])\n",
    "\n",
    "display(all_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 次の作業\n",
    "\n",
    "convert_to_trt.ipynb で学習済みモデルとTensorRT形式に変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
