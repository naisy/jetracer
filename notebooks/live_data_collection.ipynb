{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JetRacerデータ収集と学習\n",
    "このノートブックでは、JetRacerの自動走行に必要なデータを収集して、学習と予測値の確認をおこないます。   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JetRacerデータ収集\n",
    "JetRacerのデータ収集は以下の手順になります。  \n",
    "  * カメラを起動する\n",
    "  * カメラ映像をクリック可能なwidgetに表示する\n",
    "  * カメラwidgetをクリックする\n",
    "  * クリックしたx,y座標をファイル名に含めて画像をjpeg形式で保存する\n",
    "  * 収集したデータの座標を編集可能にする\n",
    "\n",
    "まずはこのノートブックの実行に必要なパッケージを読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython Libraries for display and widgets\n",
    "import ipywidgets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "import traitlets\n",
    "from traitlets import observe\n",
    "from jupyter_clickable_image_widget import ClickableImageWidget\n",
    "\n",
    "# Camera and Motor Interface\n",
    "from jetcam.utils import bgr8_to_jpeg\n",
    "from jetracer.utils import preprocess\n",
    "\n",
    "# Python basic pakcages for image annotation\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL.Image\n",
    "import re\n",
    "import threading\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# UNIXTIMEのミリセカンド表記を取得するためのラムダ関数を定義します\n",
    "current_milli_time = lambda: int(round(time.time() * 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カメラトラブル回避のために、一度カメラ用のデーモンを再起動しておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo jetson | sudo -S systemctl restart nvargus-daemon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カメラクラスをインスタンス化します。  \n",
    "widgetでのカメラ画像の表示は遅いため、widgetの負担を少なくするためにfpsは小さくしておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetcam.csi_camera import CSICamera\n",
    "# from jetcam.usb_camera import USBCamera\n",
    "\n",
    "camera = CSICamera(width=224, height=224, capture_fps=10)\n",
    "\n",
    "camera.running = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセット用のディレクトリを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = 'dataset_xy'\n",
    "\n",
    "# we have this \"try/except\" statement because these next functions can throw an error if the directories exist already\n",
    "try:\n",
    "    os.makedirs(DATASET_DIR)\n",
    "except FileExistsError:\n",
    "    print('Directories not created becasue they already exist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyterノートブックでは、前のセルで定義した関数内のprint()は表示することができないため、デバッグが困難になります。  \n",
    "そのため、ログ出力用のウィジェットを作成してprint()の代わりにログを表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 汎用レイアウトを定義\n",
    "description_style = {'description_width': 'initial'}\n",
    "widget_width = ipywidgets.Layout(width=str(camera.width)+'px')\n",
    "widget_width_half = ipywidgets.Layout(width=str(camera.width/2)+'px')\n",
    "\n",
    "# ログ表示用ウィジェット\n",
    "process_layout = ipywidgets.Layout(flex='0 1 auto', height='100px', min_height='100px', width='auto')\n",
    "process_widget = ipywidgets.Textarea(description='ログ', value='', layout=process_layout, style=description_style)\n",
    "\n",
    "process_no = 0\n",
    "def write_log(msg):\n",
    "    global process_widget, process_no\n",
    "    process_no = process_no + 1\n",
    "    process_widget.value = str(process_no) + \": \" + msg + \"\\n\" + process_widget.value\n",
    "\n",
    "display(process_widget)\n",
    "\n",
    "write_log(\"ログを表示\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カメラウィジェットをクリックしてデータを保存したときに、学習用のデータセットの情報も更新しておきたいので、カメラウィジェットを作る前にデータセットを定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy(name):\n",
    "    \"\"\"\n",
    "    name:\n",
    "        dir/xy_unixtimemillisec_x_y.jpg\n",
    "        xy_unixtimemillisec_x_y.jpg\n",
    "    \"\"\"\n",
    "    pattern = '.*xy_(\\d+)_(\\d+)_(\\d+).*'\n",
    "    result = re.match(pattern, name)\n",
    "    if result:\n",
    "        millisec = result.group(1)\n",
    "        x = result.group(2)\n",
    "        y = result.group(3)\n",
    "    else:\n",
    "        millisec = 0\n",
    "        x = 0\n",
    "        y = 0\n",
    "    return x, y\n",
    "\n",
    "def get_millisec(name):\n",
    "    \"\"\"\n",
    "    name:\n",
    "        xy_unixtimemillisec_x_y.jpg\n",
    "    \"\"\"\n",
    "    pattern = '^xy_(\\d+)_(\\d+)_(\\d+).*'\n",
    "    result = re.match(pattern, name)\n",
    "    if result:\n",
    "        millisec = result.group(1)\n",
    "        x = result.group(2)\n",
    "        y = result.group(3)\n",
    "    else:\n",
    "        millisec = 0\n",
    "        x = 0\n",
    "        y = 0\n",
    "    return millisec\n",
    "\n",
    "class XYDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, directory, random_hflips=False):\n",
    "        self.directory = directory\n",
    "        self.color_jitter = transforms.ColorJitter(0.2, 0.2, 0.2, 0.2)\n",
    "        self.random_hflips = random_hflips\n",
    "        self.refresh()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "   \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.annotations[idx]['image_path']\n",
    "        x_ratio, y_ratio = get_xy(image_path)\n",
    "        x = float(int(x_ratio)-50.0)/50.0\n",
    "        y = float(int(y_ratio)-50.0)/50.0\n",
    "\n",
    "        image = PIL.Image.open(image_path)\n",
    "\n",
    "        # ランダムに画像を水平反転する時、出力のxも対応するように反転します。デフォルトではFalseです。\n",
    "        if self.random_hflips:\n",
    "            if float(np.random.rand(1)) > 0.5:\n",
    "                image = transforms.functional.hflip(image)\n",
    "                x = -x\n",
    "\n",
    "        # 画像をモデル学習の入力用データフォーマットに変換します\n",
    "        image = self.color_jitter(image)\n",
    "        image = transforms.functional.resize(image, (224, 224))\n",
    "        image = transforms.functional.to_tensor(image)\n",
    "        image = image.numpy()[::-1].copy()\n",
    "        image = torch.from_numpy(image)\n",
    "        # ImageNetの正規化と同じパラメータでデータを正規化します\n",
    "        image = transforms.functional.normalize(image, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "        return image, torch.tensor([x, y]).float()\n",
    "\n",
    "    def refresh(self):\n",
    "        self.annotations = []\n",
    "        for image_path in glob.glob(os.path.join(self.directory, '*.jpg')):\n",
    "            x, y = get_xy(image_path)\n",
    "            self.annotations += [{\n",
    "                'image_path': image_path,\n",
    "                'x': x,\n",
    "                'y': y\n",
    "            }]\n",
    "\n",
    "dataset = XYDataset(DATASET_DIR, random_hflips=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データ収集用のカメラウィジェットと確認用のスナップショットウィジェットを定義します。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unobserve all callbacks from camera in case we are running this cell for second time\n",
    "camera.unobserve_all()\n",
    "\n",
    "# create image preview\n",
    "camera_widget = ClickableImageWidget(width=camera.width, height=camera.height)\n",
    "snapshot_widget = ClickableImageWidget(width=camera.width, height=camera.height)\n",
    "traitlets.dlink((camera, 'value'), (camera_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "no_widget = ipywidgets.IntText(description='no', style=description_style, layout=widget_width)\n",
    "\n",
    "# create widgets\n",
    "count_widget = ipywidgets.IntText(description='count', style=description_style, layout=widget_width)\n",
    "\n",
    "# manually update counts at initialization\n",
    "count_widget.value = len(glob.glob(os.path.join(DATASET_DIR, '*.jpg')))\n",
    "\n",
    "\n",
    "# カメラ画像を保存する機能を作成します\n",
    "def save_snapshot(_, content, msg):\n",
    "    global DATASET_DIR, dataset, snapshot_widget, no_widget\n",
    "    if content['event'] == 'click':\n",
    "        data = content['eventData']\n",
    "        # クリックしたx,y座標を取得します（ピクセル座標）\n",
    "        x = data['offsetX']\n",
    "        y = data['offsetY']\n",
    "        # パーセントに変換します\n",
    "        x_ratio = int((x/224)*100)\n",
    "        y_ratio = int((y/224)*100)\n",
    "        # ファイル名を決定します\n",
    "        filename = 'xy_%13d_%03d_%03d' % (current_milli_time(), x_ratio, y_ratio) + '.jpg'\n",
    "        # 保存先をディレクトリパスを含めて決定します\n",
    "        image_path = os.path.join(DATASET_DIR, filename)\n",
    "        # 画像を保存します\n",
    "        with open(image_path, 'wb') as f:\n",
    "            f.write(camera_widget.value)\n",
    "\n",
    "        # カメラ画像をsnapshot変数にコピーします\n",
    "        snapshot = camera.value.copy()\n",
    "        # クリックした座標に緑色で丸を描きます\n",
    "        snapshot = cv2.circle(snapshot, (x, y), 8, (0, 255, 0), 3)\n",
    "        # OpenCV BGR画像をjpeg画像に変換して、スナップショットウィジェットに表示します\n",
    "        snapshot_widget.value = bgr8_to_jpeg(snapshot)\n",
    "        # データファイル総数を確認します\n",
    "        count_widget.value = len(glob.glob(os.path.join(DATASET_DIR, '*.jpg')))\n",
    "        # ナンバーウィジェットにデータファイル総数を表示します\n",
    "        no_widget.value = count_widget.value\n",
    "        # データセットクラスが持つデータ情報を更新します\n",
    "        dataset.refresh()\n",
    "\n",
    "camera_widget.on_msg(save_snapshot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "スナップショットウィジェットで座標を編集できるようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(no):\n",
    "    \"\"\"\n",
    "    noは1からn番までの値で、ファイル番号を表します。\n",
    "    \"\"\"\n",
    "    global DATASET_DIR, img,load_flag,no_widget,snapshot_widget\n",
    "    filenames = os.listdir(DATASET_DIR)\n",
    "    filenames.sort()\n",
    "    if len(filenames) == 0:\n",
    "        no_widget.value = 0\n",
    "        write_log(\"データファイルが存在しません。\")\n",
    "        return\n",
    "    if no > len(filenames):\n",
    "        no = 1\n",
    "    if no < 1:\n",
    "        no = len(filenames)\n",
    "\n",
    "    no_widget.value = no\n",
    "    name = filenames[no -1]\n",
    "    write_log(str(no) + \"枚目の\" + name + \"を読込みます。\")\n",
    "    \n",
    "    x_ratio, y_ratio = get_xy(name)\n",
    "    x = int(float(x_ratio)/100*224)\n",
    "    y = int(float(y_ratio)/100*224)\n",
    "    write_log(\"x,y,name: {},{}, {}\".format(x,y,name))\n",
    "    img = cv2.imread(os.path.join(DATASET_DIR, name))\n",
    "    marked_img = img.copy()\n",
    "    marked_img = cv2.circle(marked_img, (int(x), int(y)), 8, (0, 255, 0), 3)\n",
    "    snapshot_widget.value = bgr8_to_jpeg(marked_img)\n",
    "    write_log(str(no) + \"枚目の\" + name + \"を読込みました。\")\n",
    "\n",
    "def prev_pic(c):\n",
    "    global img,load_flag\n",
    "    load_flag = True\n",
    "    no = no_widget.value\n",
    "    no = int(no) - 1\n",
    "    load_img(no)\n",
    "\n",
    "def next_pic(c):\n",
    "    global x,y,load_flag\n",
    "    load_flag = True\n",
    "    no = no_widget.value\n",
    "    no = int(no) + 1\n",
    "    load_img(no)\n",
    "\n",
    "def save_edit(_, content, msg):\n",
    "    global DATASET_DIR,dataset,img,x,y,load_flag,snapshot_widget,no_widget\n",
    "    if content['event'] == 'click' and load_flag == True:\n",
    "        #load_flag = False\n",
    "        data = content['eventData']\n",
    "        x = data['offsetX']\n",
    "        y = data['offsetY']\n",
    "        # save to disk\n",
    "        #dataset.save_entry(category_widget.value, camera.value, x, y)\n",
    "        x_ratio = int((x/224)*100)\n",
    "        y_ratio = int((y/224)*100)\n",
    "\n",
    "        filenames = os.listdir(DATASET_DIR)\n",
    "        filenames.sort()\n",
    "        old_file_name = filenames[no_widget.value -1]\n",
    "        old_file_path = os.path.join(DATASET_DIR, old_file_name)\n",
    "        write_log(\"old_file_path: {}\".format(old_file_path))\n",
    "        millisec = int(get_millisec(old_file_name))\n",
    "        new_file_name = 'xy_%13d_%03d_%03d' % (millisec, x_ratio, y_ratio) + '.jpg'\n",
    "        new_file_path = os.path.join(DATASET_DIR, new_file_name)\n",
    "        write_log(\"new_file_path: {}\".format(new_file_path))\n",
    "        os.rename(old_file_path, new_file_path)\n",
    "        \n",
    "        # display saved remarked_img\n",
    "        remarked_img = cv2.imread(new_file_path)\n",
    "        remarked_img = cv2.circle(remarked_img, (int(x), int(y)), 8, (0, 255, 0), 3)\n",
    "        snapshot_widget.value = bgr8_to_jpeg(remarked_img)\n",
    "        #count_widget.value = len(glob.glob(os.path.join(DATASET_DIR, '*.jpg')))\n",
    "        dataset.refresh()\n",
    "        write_log(\"新しい座標で保存しました。\")\n",
    "\n",
    "\n",
    "snapshot_widget.on_msg(save_edit)\n",
    "prev_pic_button = ipywidgets.Button(description='prev', layout=widget_width_half)\n",
    "next_pic_button = ipywidgets.Button(description='next', layout=widget_width_half)\n",
    "\n",
    "prev_pic_button.on_click(prev_pic)\n",
    "next_pic_button.on_click(next_pic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "左側にデータ収集用のカメラウィジェット、右側に編集機能付きのスナップショットウィジェットを表示します。  \n",
    "左側のカメラ映像をクリックすると、その時のx,y座標と画像をjpegファイルで保存します。  \n",
    "また、右側のウィジェットに保存した画像とクリックした座標を緑丸で表示します。  \n",
    "\n",
    "保存する画像ファイル名は、編集時のファイル読み込み順を固定するためのソート用としてUNIXTIMEのミリ秒表記も含めておきます。  \n",
    "また、画像サイズを変更しても同様の動作となるようにx,y座標はピクセル座標ではなく、パーセント表記に変換した値を使うことにします。\n",
    "> JetRacerは学習する左右の値はステアリング値として使用します。上下の値は学習はしていますが、自動走行には使用していません。自動走行用の多少改修することで上下の値をスロットル値として利用可能にすることもできます。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# スナップショットウィジェットと説明と表示中のファイル番号とファイル操作ボタンを垂直に配置します\n",
    "vb_snapshot_widget = ipywidgets.VBox([\n",
    "    snapshot_widget,\n",
    "    ipywidgets.Label('edit data'),\n",
    "    no_widget,\n",
    "    ipywidgets.HBox([prev_pic_button, next_pic_button])],\n",
    "    layout=ipywidgets.Layout(align_items='center')\n",
    ")\n",
    "\n",
    "display(\n",
    "    # ウィジェットを水平に配置します\n",
    "    ipywidgets.HBox([\n",
    "        # カメラウィジェットと説明とファイル総数を垂直に配置します\n",
    "        ipywidgets.VBox([\n",
    "            camera_widget,\n",
    "            ipywidgets.Label('click to collect data'),\n",
    "            count_widget\n",
    "        ], layout=ipywidgets.Layout(align_items='center')),\n",
    "        vb_snapshot_widget\n",
    "    ]),\n",
    "    # 最後にログ表示ウィジェットを配置します\n",
    "    process_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習モデルを定義します\n",
    "モデルはresnet18をベースにして、予測する値はx,yの2つとなるので、`model.fc`を変更します。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "output_dim = 2  # x, y coordinate\n",
    "\n",
    "# ALEXNET\n",
    "# model = torchvision.models.alexnet(pretrained=True)\n",
    "# model.classifier[-1] = torch.nn.Linear(4096, output_dim)\n",
    "\n",
    "# SQUEEZENET \n",
    "# model = torchvision.models.squeezenet1_1(pretrained=True)\n",
    "# model.classifier[1] = torch.nn.Conv2d(512, output_dim, kernel_size=1)\n",
    "# model.num_classes = len(dataset.categories)\n",
    "\n",
    "# RESNET 18\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Linear(512, output_dim)\n",
    "\n",
    "# RESNET 34\n",
    "# model = torchvision.models.resnet34(pretrained=True)\n",
    "# model.fc = torch.nn.Linear(512, output_dim)\n",
    "\n",
    "# DENSENET 121\n",
    "# model = torchvision.models.densenet121(pretrained=True)\n",
    "# model.classifier = torch.nn.Linear(model.num_features, output_dim)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデル読込み、保存用のボタンを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_button = ipywidgets.Button(description='save model', layout=widget_width_half)\n",
    "model_load_button = ipywidgets.Button(description='load model', layout=widget_width_half)\n",
    "model_path_widget = ipywidgets.Text(description='model', value='road_following_model.pth', style=description_style, layout=widget_width)\n",
    "\n",
    "def load_model(c):\n",
    "    start = time.time()\n",
    "    write_log(model_path_widget.value + \"の読込処理を開始します。\")\n",
    "    model.load_state_dict(torch.load(model_path_widget.value))\n",
    "    process_time = time.time() - start\n",
    "    write_log(model_path_widget.value + \"の読込処理を終了しました(処理時間:{0:.3f}秒)。\".format(process_time))\n",
    "model_load_button.on_click(load_model)\n",
    "    \n",
    "def save_model(c):\n",
    "    start = time.time()\n",
    "    write_log(model_path_widget.value + \"の書込処理を開始します。\")\n",
    "    torch.save(model.state_dict(), model_path_widget.value)\n",
    "    process_time = time.time() - start\n",
    "    write_log(model_path_widget.value + \"の書込処理を終了しました(処理時間:{0:.3f}秒)。\".format(process_time))\n",
    "model_save_button.on_click(save_model)\n",
    "\n",
    "model_widget = ipywidgets.VBox([\n",
    "    model_path_widget,\n",
    "    ipywidgets.HBox([model_load_button, model_save_button]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 予測結果を表示するウィジェットを作成\n",
    "学習後にシームレスに成果を確認するために、結果を表示するためのウィジェットを作成しておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_widget = ipywidgets.ToggleButtons(options=['stop', 'live'], description='state', value='stop', style=description_style)\n",
    "state_widget.style.button_width='50px'\n",
    "prediction_widget = ipywidgets.Image(format='jpeg', width=camera.width, height=camera.height)\n",
    "\n",
    "def live(state_widget, model, camera, prediction_widget):\n",
    "    while state_widget.value == 'live':\n",
    "        image = camera.value\n",
    "        preprocessed = preprocess(image)\n",
    "        output = model(preprocessed).detach().cpu().numpy().flatten()\n",
    "        x_pred = output[0]\n",
    "        y_pred = output[1]\n",
    "        #write_log(\"x_pred,y_pred = {},{}\".format(x_pred,y_pred))\n",
    "        x_ratio = x_pred/2 + 0.5\n",
    "        y_ratio = y_pred/2 + 0.5\n",
    "        #write_log(\"x_ratio,y_ratio = {},{}\".format(x_ratio,y_ratio))\n",
    "        x = int(camera.width * x_ratio)\n",
    "        y = int(camera.height * y_ratio)\n",
    "        #write_log(\"x,y = {},{}\".format(x,y))\n",
    "\n",
    "        prediction = image.copy()\n",
    "        prediction = cv2.circle(prediction, (int(x), int(y)), 8, (255, 0, 0), 3)\n",
    "        prediction_widget.value = bgr8_to_jpeg(prediction)\n",
    "            \n",
    "def start_live(change):\n",
    "    if change['new'] == 'live':\n",
    "        write_log(\"liveモードを開始します。\")\n",
    "        execute_thread = threading.Thread(target=live, args=(state_widget, model, camera, prediction_widget))\n",
    "        execute_thread.start()\n",
    "    else:\n",
    "        write_log(\"liveモードを停止します。\")\n",
    "\n",
    "state_widget.observe(start_live, names='value')\n",
    "\n",
    "live_execution_widget = ipywidgets.VBox([\n",
    "    prediction_widget,\n",
    "    ipywidgets.Label('live prediction'),\n",
    "    state_widget\n",
    "], layout=ipywidgets.Layout(align_items='center'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一回のミニバッチ処理で読込むデータ件数を定義します\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
    "\n",
    "# 学習用のウィジェットを定義します\n",
    "epochs_widget = ipywidgets.IntText(description='epochs', value=1, style=description_style, layout=widget_width)\n",
    "eval_button = ipywidgets.Button(description='evaluate', layout=widget_width_half)\n",
    "train_button = ipywidgets.Button(description='train', layout=widget_width_half)\n",
    "loss_widget = ipywidgets.FloatText(description='loss', style=description_style, layout=widget_width)\n",
    "progress_widget = ipywidgets.FloatProgress(min=0.0, max=1.0, description='progress', style=description_style, layout=widget_width)\n",
    "\n",
    "\n",
    "# プログレスバーを更新するクラスを定義します\n",
    "class Progress(traitlets.HasTraits):\n",
    "    value = traitlets.Float()\n",
    "    total_value = 100\n",
    "\n",
    "    @observe('value')\n",
    "    def _on_value(self, change):\n",
    "       \n",
    "        self._update_progress()\n",
    "    \n",
    "    def _update_progress(self):\n",
    "        global progress_widget\n",
    "        progress_widget.value = self.value / self.total_value\n",
    "\n",
    "# 学習と評価を実行する関数を定義します\n",
    "def train_eval(is_training):\n",
    "    global BATCH_SIZE, LEARNING_RATE, MOMENTUM, model, dataset, optimizer, eval_button, train_button, model_save_button, model_load_button, state_widget, accuracy_widget, loss_widget, progress_widget, state_widget\n",
    "    \n",
    "    try:\n",
    "        dataset.refresh()\n",
    "        progress_widget.value = 0\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            num_workers=0\n",
    "        )\n",
    "\n",
    "        # ライブ予測を停止します\n",
    "        state_widget.value = 'stop'\n",
    "        # 各種ボタン操作を無効化します\n",
    "        model_save_button.disabled = True\n",
    "        model_load_button.disabled = True\n",
    "        state_widget.disabled = True\n",
    "        train_button.disabled = True\n",
    "        eval_button.disabled = True\n",
    "        # ライブ予測スレッドが停止するまで1秒待ちます\n",
    "        time.sleep(1)\n",
    "        start = time.time()\n",
    "        if is_training:\n",
    "            model = model.train()\n",
    "            write_log(\"{}Epochの学習を開始します。\".format(epochs_widget.value))\n",
    "        else:\n",
    "            # ドロップアウトを無効にする評価モード\n",
    "            model = model.eval()\n",
    "            write_log(\"評価モードで学習を開始します(1 Epochのみ)。\")\n",
    "\n",
    "        epoch_num = 1\n",
    "        # プログレスバーの更新を定義します\n",
    "        progress = Progress()\n",
    "        progress.total_value = 8*len(dataset)/BATCH_SIZE\n",
    "        while epochs_widget.value > 0:\n",
    "            i = 0\n",
    "            sum_loss = 0.0\n",
    "            error_count = 0.0\n",
    "            epoch_start = time.time()\n",
    "            progress.value = 0\n",
    "            for images, xy in iter(train_loader):\n",
    "                progress.value += 1\n",
    "                # send data to device\n",
    "                images = images.to(device)\n",
    "                progress.value += 1\n",
    "                xy = xy.to(device)\n",
    "                progress.value += 1\n",
    "                if is_training:\n",
    "                    # zero gradients of parameters\n",
    "                    optimizer.zero_grad()\n",
    "                progress.value += 1\n",
    "\n",
    "                # execute model to get outputs\n",
    "                outputs = model(images)\n",
    "                progress.value += 1\n",
    "\n",
    "                # compute MSE loss over x, y coordinates for associated categories\n",
    "                loss = 0.0\n",
    "                loss += F.mse_loss(outputs, xy)\n",
    "                progress.value += 1\n",
    "\n",
    "                if is_training:\n",
    "                    # run backpropogation to accumulate gradients\n",
    "                    loss.backward()\n",
    "\n",
    "                    # step optimizer to adjust parameters\n",
    "                    optimizer.step()\n",
    "                progress.value += 1\n",
    "\n",
    "                # increment progress\n",
    "                i += 1\n",
    "                sum_loss += float(loss)\n",
    "                loss_widget.value = sum_loss / i\n",
    "                progress.value += 1\n",
    "                \n",
    "            if is_training:\n",
    "                process_time = time.time() - epoch_start\n",
    "                write_log(str(epoch_num)+\"Epoch目の学習が終了しました(処理時間:{0:.3f}秒)。\".format(process_time))\n",
    "                epochs_widget.value -= 1\n",
    "                epoch_num += 1\n",
    "            else:\n",
    "                break\n",
    "    except e:\n",
    "        pass\n",
    "    model = model.eval()\n",
    "    \n",
    "    model_save_button.disabled = False\n",
    "    model_load_button.disabled = False\n",
    "    state_widget.disabled = False\n",
    "    train_button.disabled = False\n",
    "    eval_button.disabled = False\n",
    "   \n",
    "    process_time = time.time() - start\n",
    "    if is_training:\n",
    "        write_log(\"すべての学習が終了しました(トータルの処理時間:{0:.3f}秒)。\".format(process_time))\n",
    "    else:\n",
    "        write_log(\"すべての評価が終了しました(トータルの処理時間:{0:.3f}秒)。\".format(process_time))\n",
    "        \n",
    "    state_widget.value = 'live'\n",
    "    \n",
    "train_button.on_click(lambda c: train_eval(is_training=True))\n",
    "eval_button.on_click(lambda c: train_eval(is_training=False))\n",
    "    \n",
    "train_eval_widget = ipywidgets.VBox([\n",
    "    epochs_widget,\n",
    "    progress_widget,\n",
    "    loss_widget,\n",
    "    ipywidgets.HBox([train_button, eval_button])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## それでは学習しましょう！\n",
    "最初は1エポックで学習します。ここでプログラムが動作するか確認することができます。  \n",
    "次に、10エポックで学習します。ライブ予測画面に青丸が表示されることを確認してください。この青丸が予測したx,y座標になります。  \n",
    "\n",
    "そこまで確認できたら、あとはデータを取って学習して、うまく精度が出ないところを重点的にデータを集めることで、精度をあげることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vb_data_collection_widget = ipywidgets.VBox([\n",
    "        camera_widget,\n",
    "        ipywidgets.Label('click to collect data'),\n",
    "        count_widget,\n",
    "        train_eval_widget,\n",
    "        model_widget,\n",
    "    ], layout=ipywidgets.Layout(align_items='center'))\n",
    "\n",
    "\n",
    "\n",
    "all_widget = ipywidgets.VBox([\n",
    "\n",
    "    ipywidgets.HBox([vb_data_collection_widget,\n",
    "                     vb_snapshot_widget,\n",
    "                     live_execution_widget]), \n",
    "\n",
    "    process_widget\n",
    "])\n",
    "\n",
    "display(all_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 次の作業\n",
    "\n",
    "convert_to_trt.ipynb で学習済みモデルとTensorRT形式に変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
